# Spark Clusters

## Definition:

- Consists of a driver node and worker nodes
- Code initially communicates with driver nodes and then work is distributed across worker nodes
- As workload is [[parallelizable|parallelized]] this reduces processing time
- Requires us to choose between [[CPU]] and [[GPU]] compute
---
Links :: [[DP-100]] [[Computer Science]] [[Cloud]]
Reference ::  [[Azure]]
Type :: #atom
Creator ::
TAF ::
Discussion ::
Dis_Topic :: 
Resolved ::
Date :: 2024-09-08 07:40